# set copym to '1'
books$copym[i] <- 1
# get number of copies of textbook via random uniform sample between 1 and 3
tb_copies <- round(runif(1, min = 1, max = 3))
# create copies of textbook directly adjacent to master copy
k <- i + 1
while (k <= Nvols & (k <= i + tb_copies) ) {
books$btype[k] <- 't'
books$dupeof[k] <- books$book_id[i]
# set width of copies to width of master copy
books$width[k] <- books$width[i]
k <- k + 1
}
} # end if
} # end for
View(books)
library(triangle)
Nvols <- 1000
# set total number of shelves
Nshelves <- 50
# set length of shelf in inches
shelf_width <- 36
# set min shelf free space for each shelf as a percentage of total shelf width
sfree_space <- 0.1
# set max shelf space consumed by books
max_shelved <- shelf_width - (shelf_width * sfree_space)
# set the percentage of books that are master copies of textbooks
textb_masters <- 0.05
# ======================================================
# Initialize 'books' data frame
# ======================================================
# book_id: unique ID for each book
# btype: indicates whether book is textbook or non-text; 't' for textbook, 'n' for non-textbook
# copym: binary 0/1 flag indicating whether a textbook is the master copy for that book
# dupeof: If a given item in books dataframe is a copy of a textbook but not the master
#         copy, dupeof will contain the book_id of the master copy. This field will allow
#         for de-duplication of textbooks that have been deemed out-of-date.
# shelf_id: ID of shelf book is assigned to (zero initially)
# width: width of book (is set via random sampling below)
# chkdout: binary 0/1 flag; 0 = not checked out; 1 = book has been checked out
# dedupe: binary 0/1 flag; 0 = no need to dedupe; 1 = dedupe when checked back in
books <- data.frame(book_id = 1:Nvols, btype = character(Nvols), copym = numeric(Nvols),
dupeof = numeric(Nvols), shelf_id = numeric(Nvols), width = numeric(Nvols),
chkdout =numeric(Nvols), dedupe = numeric(Nvols), stringsAsFactors = FALSE)
# set book widths: distrib is between 1-2 inches; assume TRIANGULAR distribution
# NOTE: distribution to be sampled from can be changed to anything we want
a <- 1 # set lower bound of triangular distribution
b <- 2 # set upper bound of triangular distribution
# now sample from triangular distribution: Number of samples = number of books ('Nvols')
books$width <- rtriangle(Nvols, a, b, (a + b)/b )
books$btype <- 'n'
# then set percentage of books to textbook to textbook master copies
# start by picking random sample of books
tbm <- sort(sample(books$book_id, (Nvols * textb_masters), replace = FALSE))
# For each book_id in tbm, set btype = 't', copym = 1, and create copies of
#
for (i in tbm) {
# if the book has not already been set to type 't', proceed
# otherwise ignore and continue
if (books$btype[i] != 't') {
# set btype to 't'
books$btype[i] <- 't'
# set copym to '1'
books$copym[i] <- 1
# get number of copies of textbook via random uniform sample between 1 and 3
tb_copies <- round(runif(1, min = 1, max = 3))
# create copies of textbook directly adjacent to master copy
k <- i + 1
while (k <= Nvols & (k <= i + tb_copies) ) {
books$btype[k] <- 't'
books$dupeof[k] <- books$book_id[i]
# set width of copies to width of master copy
books$width[k] <- books$width[i]
k <- k + 1
}
} # end if
} # end for
View(books)
library(knitr)
# Euler's Method
# initialize data frame to store results
res <- data.frame(x = numeric(5), y = numeric(5))
rownames(res) <- c("t0", "t1", "t2", "t3", "t4")
# initialize x0 and y0
res$x[1] <- 1/2
res$y[1] <- 1
# initialize delta
delta <- 1
# now loop starting at 2 since res[1] contains values of X0 and y0 at t0
for (i in 2:5) {
# dx/dt = x - xy - 3/4*y
res$x[i] <- res$x[(i-1)] + ( res$x[(i-1)] - (res$x[(i-1)] * res$y[(i-1)]) -
(3/4 * res$y[(i-1)] ) ) * delta
# dy/dt = xy - y - 3/4*x
res$y[i] <- res$y[(i-1)] + ( (res$x[(i-1)] * res$y[(i-1)]) -
res$y[(i-1)] - (3/4 * res$x[(i-1)] ) ) * delta
}
res2 <- data.frame(x = numeric(5), y = numeric(5))
rownames(res2) <- c("t0", "t1", "t2", "t3", "t4")
# initialize x0 and y0
res2$x[1] <- 1/2
res2$y[1] <- 1
# initialize delta
delta <- 1
# now loop starting at 2 since res[1] contains values of X0 and y0 at t0
for (i in 2:5) {
# find x*_(n+1). Use variable 'xsnp1' to indicate "x*_n+1"
# equation is: x_n+1 = x_n + (x_n + (x_n * y_n) - 3/4(x_n) ) * delta
xsnp1 <- res2$x[(i-1)] + ( res2$x[(i-1)] - (res2$x[(i-1)] * res2$y[(i-1)]) -
(3/4 * res2$y[(i-1)] ) ) * delta
# find y*_(n+1). Use variable 'ysnp1' to indicate "y*_n+1"
# equation is: y_n+1 = y_n + ( (x_n * y_n) - y_n - 3/4(x_n) ) * delta
ysnp1 <- res2$y[(i-1)] + ( (res2$x[(i-1)] * res2$y[(i-1)]) -
res2$y[(i-1)] - (3/4 * res2$x[(i-1)] ) ) * delta
# calculate x - xy - 3/4*y WITHOUT multiplying by delta OR adding x_n to result
fxn <- res2$x[(i-1)] - (res2$x[(i-1)] * res2$y[(i-1)]) - (3/4 * res2$y[(i-1)] )
# calculate xy - y - 3/4*x WITHOUT multiplying by delta OR adding y_n to result
gyn <- (res2$x[(i-1)] * res2$y[(i-1)]) - res2$y[(i-1)] - (3/4 * res2$x[(i-1)] )
# calculate f(x*_n+1)
fxsnp1 <- xsnp1 - xsnp1*ysnp1 - 0.75*ysnp1
# calculate g(y*_n+1)
gysnp1 <- xsnp1 * ysnp1 - ysnp1 - 0.75*xsnp1
# now calculate approximations for x and y
res2$x[i] <- res2$x[(i-1)] + ( (fxn + fxsnp1) * (delta/2) )
res2$y[i] <- res2$y[(i-1)] + ( (gyn + gysnp1) * (delta/2) )
}
colnames(res1) <- c("Euler-X","Euler-Y")
colnames(res) <- c("Euler-X","Euler-Y")
View(res)
colnames(res2) <- c("Imp_Euler-X","Imp_Euler-Y")
restab <- cbind(res, res2)
kable(restab)
res <- data.frame(x = numeric(5), y = numeric(5))
rownames(res) <- c("t0", "t1", "t2", "t3", "t4")
# initialize x0 and y0
res$x[1] <- 1/2
res$y[1] <- 1
# initialize delta
delta <- 1
# now loop starting at 2 since res[1] contains values of X0 and y0 at t0
for (i in 2:5) {
# dx/dt = x - xy - 3/4*y
res$x[i] <- res$x[(i-1)] + ( res$x[(i-1)] - (res$x[(i-1)] * res$y[(i-1)]) -
(3/4 * res$y[(i-1)] ) ) * delta
# dy/dt = xy - y - 3/4*x
res$y[i] <- res$y[(i-1)] + ( (res$x[(i-1)] * res$y[(i-1)]) -
res$y[(i-1)] - (3/4 * res$x[(i-1)] ) ) * delta
}
res2 <- data.frame(x = numeric(5), y = numeric(5))
rownames(res2) <- c("t0", "t1", "t2", "t3", "t4")
# initialize x0 and y0
res2$x[1] <- 1/2
res2$y[1] <- 1
# initialize delta
delta <- 1
# now loop starting at 2 since res[1] contains values of X0 and y0 at t0
for (i in 2:5) {
# find x*_(n+1). Use variable 'xsnp1' to indicate "x*_n+1"
# equation is: x_n+1 = x_n + (x_n + (x_n * y_n) - 3/4(x_n) ) * delta
xsnp1 <- res2$x[(i-1)] + ( res2$x[(i-1)] - (res2$x[(i-1)] * res2$y[(i-1)]) -
(3/4 * res2$y[(i-1)] ) ) * delta
# find y*_(n+1). Use variable 'ysnp1' to indicate "y*_n+1"
# equation is: y_n+1 = y_n + ( (x_n * y_n) - y_n - 3/4(x_n) ) * delta
ysnp1 <- res2$y[(i-1)] + ( (res2$x[(i-1)] * res2$y[(i-1)]) -
res2$y[(i-1)] - (3/4 * res2$x[(i-1)] ) ) * delta
# calculate x - xy - 3/4*y WITHOUT multiplying by delta OR adding x_n to result
fxn <- res2$x[(i-1)] - (res2$x[(i-1)] * res2$y[(i-1)]) - (3/4 * res2$y[(i-1)] )
# calculate xy - y - 3/4*x WITHOUT multiplying by delta OR adding y_n to result
gyn <- (res2$x[(i-1)] * res2$y[(i-1)]) - res2$y[(i-1)] - (3/4 * res2$x[(i-1)] )
# calculate f(x*_n+1)
fxsnp1 <- xsnp1 - xsnp1*ysnp1 - 0.75*ysnp1
# calculate g(y*_n+1)
gysnp1 <- xsnp1 * ysnp1 - ysnp1 - 0.75*xsnp1
# now calculate approximations for x and y
res2$x[i] <- res2$x[(i-1)] + ( (fxn + fxsnp1) * (delta/2) )
res2$y[i] <- res2$y[(i-1)] + ( (gyn + gysnp1) * (delta/2) )
}
restab <- data.frame(Euler-X = res$x, Euler-Y = res$y,
Imp_Euler-X = res2$x, Imp_Euler-Y = res2$y)
restab <- data.frame("Euler-X" = res$x, "Euler-Y" = res$y,
"Imp_Euler-X" = res2$x, "Imp_Euler-Y" = res2$y)
View(restab)
kable(restab)
sum_cards <- function(hand) {
aces <- FALSE
ace_locs <- numeric()
sum <- 0
# if the hand is only 2 cards, just sum and exit
if (length(hand) == 2) {
sum <- hand[1] + hand[2]
return(sum)
}
# find aces
for (k in 1:length(hand)) {
if(hand[k] == 11) {
aces <- TRUE
ace_locs <- c(ace_locs, k)
}
}
# if no aces were found, sum all items and return
if (aces == FALSE) {
for (i in hand) {
sum <- sum + i
}
return(sum)
}
# otherwise aces were found so first sum items that are NOT aces
not_aces <- subset(hand, !(hand %in% c(11)))
for (i in not_aces) {
sum <- sum + i
}
# if sum of non-aces > 10 all aces must be treated as 1's
if (sum > 10) {
for (i in ace_locs) {
sum <- sum + 1
}
return(sum)
}
# if sum of non-aces <= 9, need to check count of aces.
# If > 1 one can be treated as 11 while other must be treated as 1
if (sum <= 9 & length(ace_locs) > 1) {
sum <- sum + 11
for (i in 1:(length(ace_locs) - 1)) {
sum <- sum + 1
}
return(sum)
}
# if sum of non-aces == 10, need to check count of aces.
# if == 1, then add 11 to sum and exit. if > 1, treat all aces as 1's
if (sum == 10 & length(ace_locs) == 1) {
sum <- sum + 11
return(sum)
} else {
for (i in 1:length(ace_locs)) {
sum <- sum + 1
}
return(sum)
}
}
player_h <- function(p_hand, cards, i, p_stand){
ncards <- length(cards)
stand <- FALSE
while (stand != TRUE) {
# sum current hand
current <- sum_cards(p_hand)
# if card index == number of cards in decks, time to stop
if (i == ncards) {
stand <- TRUE
# else if hand is < p_stand value, take another card
} else if (current < p_stand) {
i <- i + 1
p_hand <- c(p_hand, cards[i])
} else {
stand <- TRUE
}
} # end while stand != TRUE
return(c(current, i))
}
dealer_h <- function(d_hand, cards, i){
ncards <- length(cards)
stand <- FALSE
while (stand != TRUE) {
# sum current hand
current <- sum_cards(d_hand)
# if card index == number of cards in decks, time to stop
if (i == ncards) {
stand <- TRUE
# else if hand is <= 16, take another card
} else if (current <= 16) {
i <- i + 1
d_hand <- c(d_hand, cards[i])
} else {
stand <- TRUE
}
} # end while stand != TRUE
return(c(current, i))
}
play_bj <- function(cards, bet, p_stand){
# initialize the number of cards to be played
ncards <- length(cards)
# initialize index for cards
i <- 0
# initialize winnings accummulator
winnings <- 0
# now loop until all cards used
while (i < ncards) {
# New hand needed: check to see whether at least 4 cards remain unused
if (i <= (ncards - 4)) {
#### Deal 2 cards to player
# increment card index
i <- i + 2
p_hand <- c(cards[i-1], cards[i])
### Deal 2 cards to dealer
# increment card index
i <- i + 2
d_hand <- c(cards[i-1], cards[i])
} else {
# else cards are exhausted so exit
return(winnings)
}
#### logic for player's hand
p_res <- player_h(p_hand, cards, i, p_stand)
# update card index
i <- p_res[2]
# if player didn't go over 21 then apply dealer hand logic
if (p_res[1] <= 21) {
d_res <- dealer_h(d_hand, cards, i)
# update card index
i <- d_res[2]
}
# ---------------------------------------------------------------
# now compare player's hand to dealer's hand to find out who won
# if player hand exceeded 21 subtract 2 from winnings
if (p_res[1] > 21) {
winnings <- winnings - 2
# else if dealer went over 21 dealer has lost so add 2 to winnings
} else if (d_res[1] > 21) {
winnings <- winnings + 2
# else if player hand > dealer hand add 2 to winnings
} else if (p_res[1] > d_res[1]) {
winnings <- winnings + 2
# else if player hand < dealer hand subtract 2 from winnings
} else if (p_res[1] < d_res[1]) {
winnings <- winnings - 2
}
} # end while (i < ncards)
return(winnings)
}
set.seed(123)
# set number of 2-deck sets to play
N <- 12
# set size of bets
bet <- 2
# set hand total for player to stand at
p_stand <- 16
# generate a deck of cards
deck <- rep(c(2:10, 10, 10, 10, 11), 4)
# create a 2 deck set of cards
two_d <- rep(deck,2)
# create a vector to store results of play
res <- data.frame(N = 1:12, winnings = numeric(N))
for (i in 1:N){
# shuffle 2 new decks of cards
s_decks <-sample(two_d,length(two_d), replace = FALSE)
s_decks
# play until 2 decks are exhausted
res$winnings[i] <- play_bj(s_decks, bet, p_stand)
}
# create a table of winnings for each iteration
iteration <- 1:N
kable(data.frame(iteration, res$winnings))
# average the winnings and print to screen
avg_winnings <- mean(res$winnings)
message(paste("Average Winnings per Hand = ", avg_winnings))
iters <- 1000
# create a vector to store results of play
res2 <- data.frame(N = 1:iters, avg_winnings = numeric(iters))
for (k in 1:iters) {
for (i in 1:N){
# shuffle 2 new decks of cards
s_decks <-sample(two_d,length(two_d), replace = FALSE)
s_decks
# play until 2 decks are exhausted
res$winnings[i] <- play_bj(s_decks, bet, p_stand)
} # for i
# save the average the winnings to the results vector
res2$avg_winnings[k] <- mean(res$winnings)
} # for k
summary(res2$avg_winnings)
times <- c(1.88, 0.54, 1.90, 0.15, 0.02,
2.81, 1.50, 0.53, 2.62, 2.67,
3.53, 0.53, 1.80, 0.79, 0.21,
0.80, 0.26, 0.63, 0.36, 2.03,
1.42, 1.28, 0.82, 2.16, 0.05,
0.04, 1.49, 0.66, 2.03, 1.00,
0.39, 0.34, 0.01, 0.10, 1.10,
0.24, 0.26, 0.45, 0.17, 4.29,
0.80, 5.50, 4.91, 0.35, 0.36,
0.90, 1.03, 1.73, 0.38, 0.48)
(lmbda <- 1/mean(times))
k <- 6
p <- 1/k
# initialize vector to store values of endpoints
endpoints <- numeric(k + 1)
# find each endpoint's value
for (i in 0:k) {
endpoints[i+1] <- round( (-1/lmbda) * log(1 - (i * p)), 2)
}
# add the maximum value as the upper bound for the intervals
endpoints[k+1] <- max(times)
endpoints
h1 <- hist(times, breaks = endpoints, xlim = c(0,6), xlab = "Intervals", main = "Histogram of Service Times", probability = TRUE, yaxt='n', col = "yellow")
h1$counts
setwd("c:/users/hammer/Documents/github/Sim_Project")
library(triangle)
Nvols <- 1000
# set total number of shelves
Nshelves <- 50
# set length of shelf in inches
shelf_width <- 36
# set min shelf free space for each shelf as a percentage of total shelf width
sfree_space <- 0.1
# set max shelf space consumed by books
max_shelved <- shelf_width - (shelf_width * sfree_space)
# set the percentage of books that are master copies of textbooks
textb_masters <- 0.05
books <- data.frame(book_id = 1:Nvols, btype = character(Nvols), copym = numeric(Nvols),
dupeof = numeric(Nvols), shelf_id = numeric(Nvols), width = numeric(Nvols),
chkdout =numeric(Nvols), dedupe = numeric(Nvols), stringsAsFactors = FALSE)
# set book widths: distrib is between 1-2 inches; assume TRIANGULAR distribution
# NOTE: distribution to be sampled from can be changed to anything we want
a <- 1 # set lower bound of triangular distribution
b <- 2 # set upper bound of triangular distribution
# now sample from triangular distribution: Number of samples = number of books ('Nvols')
books$width <- rtriangle(Nvols, a, b, (a + b)/b )
books$btype <- 'n'
# then set percentage of books to textbook to textbook master copies
# start by picking random sample of books
tbm <- sort(sample(books$book_id, (Nvols * textb_masters), replace = FALSE))
# For each book_id in tbm, set btype = 't', copym = 1, and create copies of
#
for (i in tbm) {
# if the book has not already been set to type 't', proceed
# otherwise ignore and continue
if (books$btype[i] != 't') {
# set btype to 't'
books$btype[i] <- 't'
# set copym to '1'
books$copym[i] <- 1
# get number of copies of textbook via random uniform sample between 1 and 3
tb_copies <- round(runif(1, min = 1, max = 3))
# create copies of textbook directly adjacent to master copy
k <- i + 1
while (k <= Nvols & (k <= i + tb_copies) ) {
books$btype[k] <- 't'
books$dupeof[k] <- books$book_id[i]
# set width of copies to width of master copy
books$width[k] <- books$width[i]
k <- k + 1
}
} # end if
} # end for
# check results: how many textbooks (including copies) have been created?
sum(books$btype == 't')
shelves <- data.frame(shelf_id = 1:Nshelves, in_use = numeric(Nshelves),
perc_used = numeric(Nshelves), stringsAsFactors = FALSE)
k <- 1
# sum book widths to ensure they don't exceed (max shelf width - free_space)
for (i in 1: Nshelves) {
# while space used on shelf < max space consumed by books and book index < Nvols
while ((shelves$in_use[i] + books$width[k]) < max_shelved & (k <= Nvols) ) {
# assign shelf to next book
books$shelf_id[k] <- shelves$shelf_id[i]
# add width of book to total used on current shelf
shelves$in_use[i] <- shelves$in_use[i] + books$width[k]
k <- k + 1
} # end while
} # end for
# now check results
shelves
c_out <- sample(books$book_id, (Nvols * .10), replace = FALSE)
# For each book_id in c_out, set chkdout = 1 and subtract
# book width from shelf space used for appropriate shelf_id
for (i in c_out) {
# set chkdout flag to 1
books$chkdout[i] <- 1
# subtract width of chkdout book from space in use on its assigned shelf
shelves$in_use[books$shelf_id[i]] <- shelves$in_use[books$shelf_id[i]] - books$width[i]
}
# check results: should be 10% of books set the chkdout == 1
sum(books$chkdout == 1)
source("setup.R")   # these need to be in the same folder...
source("methods.R")
data = setup(nvols,nshelves,shelf_width,sfree_space,textb_masters) # returns list, need to set to two dfs
nvols=1000
nshelves=50
data = setup(nvols,nshelves,shelf_width,sfree_space,textb_masters)
books = data$books
shelves = data$shelves
View(books)
counter = 0
full_count = 0
reshelf_thresh = 5
books = weeding(books,0.02)
View(books)
data = setup(nvols,nshelves,shelf_width,sfree_space,textb_masters)
books = data$books
shelves = data$shelves
perc=0.02
round(nrow(books) * perc)
n_to_pull = round(nrow(books) * perc)
-sample(which(!books$chkdout), n_to_pull)
books = books[-sample(which(!books$chkdout), n_to_pull), ]
View(books)
View(books)
data = setup(nvols,nshelves,shelf_width,sfree_space,textb_masters)
books = data$books
shelves = data$shelves
books = weeding(books,0.02)
View(books)
nrow(books)
View(books)
View(books)
rownames(books) <- 1:nrow(books)
source("setup.R")   # these need to be in the same folder...
source("methods.R")
data = setup(nvols,nshelves,shelf_width,sfree_space,textb_masters)
books = data$books
shelves = data$shelves
books = weeding(books,0.02)
View(books)
View(shelves)
